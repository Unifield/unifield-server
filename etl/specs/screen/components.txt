Legend on performance:
* Streamline: when one record is in input, then it goes directly to output
* Semi-Streamline: some inputs elements are stored and the output is returned
  when an element is computed
* Bloc: all inputs elements are stored and the output is return at the end
  of the complete process

Note:
All components will store these processing information on themselves and route
the the channel called 'Main Log':
* time, number input, number output, start date, end date, time/record


etl.component.diff
------------------

Takes 2 flows in input and detect a difference between these two flows
using computed keys (based on data records) to compare elements that may not
have to be in the same order.

Type: Data Component
Computing Performance: Semi-Streamline
Input Flows: 2
* main: The main flow
* .*: the second flow
Output Flows: 0-x
* same: return all elements that are the same in both input flows
* updated: return all updated elements
* removed: return all elements that where in main and not in the second flow
* added: return all elements from the second flow that are not in main channel

etl.component.reverse
---------------------

Receive a flow in input and return the same flow in output, in the same channel
name but in reverse orders. The first elements from input becomes the latests
elements sent in output.

Type: Data Component
Computing Performance: Bloc
Input Flows: 0-x
* .*: the main data flow
Output Flows: 0-y
* .*: the returned data flow, in the same channel name than input

etl.component.subjob
--------------------

When entering in this component, it trigger the beginning of a new job, linked
in this component. This allows you to create complex jobs that are composed of
different subjobs. Use it with trigger transitions.

Type: Job Component
Computing Performance: /
Input Flows: 0-x
* .*: do nothing
Output Flows: 0-x
* .*: output no data, just trigger signals

etl.component.dummy
-------------------

A component that do nothing.

Type: Data Component
Computing Performance: Streamline
Input Flows: 0-x
* .*: receive data
Output Flows: 0-y
* .*: output nothing


etl.component.aggregate_sorted
------------------------------

This component is used to give aggregate result from sorted input. Records
having the same key columns will be aggregated in one record, others are columns
are computed (sums, average, count, ...) Use this component if records are
sorted accorded to keys, because it is much more faster than the
etl.component.aggregate_unsorted as it works in streamline. If several channels
are provided in input, it return one aggregated flow in output per input channel,
with the same name.

Type: Data Component
Computing Performance: Streamline
Input Flows: 0-y
* main: The main flow
Output Flows: 0-x
* .*: return aggregated result with channel of same name than input


etl.component.aggregate_unsorted
--------------------------------

This component is used to give aggregate result from sorted input. Records
having the same key columns will be aggregated in one record, others are columns
are computed (sums, average, count, ...) Use this component if records are
unsorted. It output all the results at the end of the input process of a channel.

Type: Data Component
Computing Performance: Bloc
Input Flows: 0-y
* main: The main flow
Output Flows: 0-x
* .*: return the main flow with aggregated result

etl.component.csv_input
-----------------------

This component is used to read csv file data.

Type: Data Component
Computing Performance: Streamline
Input Flows: 0
* .* : nothing
Output Flows: 0-x
* .* : return the main flow with data from csv file

etl.component.csv_output
------------------------

This component use to store data into csv file

Type: Data Component
Computing Performance: Streamline
Input Flows: 0-x
* .* : the main data flow with input data
Output Flows: 0-1
* main : return all data

etl.component.row_filter (etl.component.simple_filter)
------------------------

This component use to filter records from given input

Type: Data Component
Computing Performance: Semi-Streamline
Input Flows: 1
* .* : the main data flow with input data
Output Flows: 0-x
* .* : return the main flow with filtering result







